# -*- coding: utf-8 -*-
"""lab3ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IYyvpA45BnonQZp7rN-4LoFJAyWhUsgX
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("drive/My Drive/code_ques.csv")
df.head()

"""Since our dataset has multiclass classification, we narrow it down to binary classification as follows:
Scores 1-5: class 0,
Scores 6-10: class 1
"""

df.shape

print(df.columns.values)

for col in df.columns:
  if df[col].isnull().sum()>0:
    print(col)
    print(df[col].isnull().sum())

df.dropna(inplace=True)

df.shape

df.dtypes

df['Final_score'] = np.where(df['score'] > 5, 1, 0)

df.shape
df.dtypes

score_0 = df[df['Final_score'] == 0]
score_1 = df[df['Final_score'] == 1]

mean_0 = np.mean(score_0.drop(columns=['Final_score','score']), axis=0)
mean_1 = np.mean(score_1.drop(columns=['Final_score', 'score']), axis=0)

std_0 = np.std(score_0.drop(columns=['Final_score','score']), axis=0)
std_1 = np.std(score_1.drop(columns=['Final_score', 'score']), axis=0)

# Calculate intraclass spread
intra_class_spread_0 = std_0
intra_class_spread_1 = std_1

# Calculate interclass distance
interclass_distance = np.linalg.norm(mean_0 - mean_1)

print("Mean for class with scores 1 to 5:", mean_0)
print("Mean for class with scores 6 to 10:", mean_1)
print("\nStandard deviation for class with scores 1 to 5:", std_0)
print("Standard deviation for class with scores 6 to 10:", std_1)
print("\nIntraclass spread for class with scores 1 to 5:", intra_class_spread_0)
print("Intraclass spread for class with scores 6 to 10:", intra_class_spread_1)
print("\nInterclass distance between both the score classes:", interclass_distance)

# Calculate histogram data and bin edges
hist, bin_edges = np.histogram(df['1'], bins=10)

# Calculate mean and variance
mean_v1 = np.mean(df['1'])
variance_v1 = np.var(df['1'])

# Plotting the histogram
plt.hist(df['1'], bins=bin_edges, edgecolor='k', alpha=0.7)
plt.xlabel('Vector 1')
plt.ylabel('Frequency')
plt.title('Vector 1 density analysis')

# Display the mean and variance
plt.axvline(x=mean_v1, color='r', linestyle='dashed', linewidth=1, label='Mean')
plt.axvline(x=mean_v1 + np.sqrt(variance_v1), color='g', linestyle='dashed', linewidth=1, label='Std Dev')
plt.axvline(x=mean_v1 - np.sqrt(variance_v1), color='g', linestyle='dashed', linewidth=1)
plt.legend()
plt.show()

print(f"Mean: {mean_v1}")
print(f"Variance: {variance_v1}")

x1 = df['1']
y1 = df['2']

# Calculate Minkowski distances for r from 1 to 10
r_values = range(1, 11)
distances = []

for r in r_values:
    distance = np.linalg.norm(x1 - y1, ord=r)
    distances.append(distance)

# Plot the Minkowski distances
plt.plot(r_values, distances, marker='o')
plt.xlabel('r (Order of Minkowski Distance)')
plt.ylabel('Distance')
plt.title('Minkowski Distance vs r')
plt.show()

X=df.iloc[:,:]
X=X.drop(['score','Final_score'],axis=1)
print(X.shape)
y=df['Final_score']
print(y.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

from sklearn.neighbors import KNeighborsClassifier

# Initialize the k-NN classifier with k=3
neigh = KNeighborsClassifier(n_neighbors=3)

# Train the classifier using the training set
neigh.fit(X_train, y_train)

# Assuming you have already trained the k-NN classifier 'neigh' and have X_test and y_test available
accuracy = neigh.score(X_test, y_test)
print(f"Accuracy of the k-NN classifier: {accuracy:.2f}")

X_test

X_train = X_train.reset_index(drop=True)
X_test = X_test.reset_index(drop=True)
y_train = y_train.reset_index(drop=True)
y_test = y_test.reset_index(drop=True)

X_test

y_test

# Assuming you have already trained the k-NN classifier 'neigh' and have X_test available
# Let's say you want to predict the class for the first test vector
test_vector = X_test.loc[2, ]  # Replace 0 with the index of the specific test vector you want to predict

predicted_class = neigh.predict([test_vector])
print(f"The predicted class for the test vector is: {predicted_class[0]}")

from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Assuming you have X_train, y_train, X_test, and y_test available

# Initialize the NN classifier with k=1
nn_classifier = KNeighborsClassifier(n_neighbors=1)
nn_classifier.fit(X_train, y_train)

# Initialize the k-NN classifier with k=3
knn_classifier = KNeighborsClassifier(n_neighbors=3)
knn_classifier.fit(X_train, y_train)

# Initialize arrays to store accuracy values
k_values = range(1, 12)
accuracy_nn = []
accuracy_knn = []

for k in k_values:
    # Train k-NN classifiers with different values of k
    knn_classifier = KNeighborsClassifier(n_neighbors=k)
    knn_classifier.fit(X_train, y_train)

    # Predict using both NN and k-NN classifiers
    y_pred_nn = nn_classifier.predict(X_test)
    y_pred_knn = knn_classifier.predict(X_test)

    # Calculate and store accuracy scores
    accuracy_nn.append(accuracy_score(y_test, y_pred_nn))
    accuracy_knn.append(accuracy_score(y_test, y_pred_knn))

# Plot the accuracy results
plt.plot(k_values, accuracy_nn, label='NN (k=1)')
plt.plot(k_values, accuracy_knn, label='k-NN (k=1 to 11)')
plt.xlabel('k (Number of Neighbors)')
plt.ylabel('Accuracy')
plt.title('Accuracy vs k for NN and k-NN Classifiers')
plt.legend()
plt.show()
print('Accuracy for nn classifier:',accuracy_nn[0])
print('Accuracy for k-nn classifier:',accuracy_knn)

y_train_pred = knn_classifier.predict(X_train)
y_train_true = y_train
y_test_pred = knn_classifier.predict(X_test)
y_test_true = y_test

from sklearn.metrics import confusion_matrix, classification_report

# Assuming you have 'y_train_true', 'y_train_pred', 'y_test_true', and 'y_test_pred' available

# Confusion Matrix and Classification Report for Training Data
confusion_matrix_train = confusion_matrix(y_train_true, y_train_pred)
classification_report_train = classification_report(y_train_true, y_train_pred)

# Confusion Matrix and Classification Report for Test Data
confusion_matrix_test = confusion_matrix(y_test_true, y_test_pred)
classification_report_test = classification_report(y_test_true, y_test_pred)

print("Confusion Matrix for Training Data:")
print(confusion_matrix_train)
print("\nClassification Report for Training Data:")
print(classification_report_train)

print("\nConfusion Matrix for Test Data:")
print(confusion_matrix_test)
print("\nClassification Report for Test Data:")
print(classification_report_test)

from sklearn.metrics import f1_score
train_f1_score = f1_score(y_train_true,y_train_pred)
print("Training F1-Score:", train_f1_score)

test_f1_score = f1_score(y_test_true,y_test_pred)
print("Testing F1-Score:", test_f1_score)

threshold = 0.2

if abs(train_f1_score - test_f1_score) < threshold:

    outcome = "Regular Fit"

elif train_f1_score > test_f1_score:

    outcome = "Overfitting"

else:

    outcome = "Underfitting"



# Print the learning outcome

print("Model Learning Outcome:", outcome)

"""To determine the class separability

1. Accuracy score using clustering method
"""

from sklearn.cluster import KMeans

# Assuming X is your data
kmeans = KMeans(n_clusters=2, random_state=42)
kmeans.fit(X)
cluster_labels = kmeans.labels_

from sklearn.metrics import accuracy_score

# Assuming y is your actual class labels
accuracy = accuracy_score(y, cluster_labels)
print("Accuracy:", accuracy)

"""2. Statistical tests and inferring from p value"""

from scipy.stats import ttest_ind

class_0_data = df.loc[df['Final_score'] == 0, '0']
class_1_data = df.loc[df['Final_score'] == 1, '0']

t_statistic, p_value = ttest_ind(class_0_data, class_1_data)
print("T-statistic:", t_statistic)
print("P-value:", p_value)

"""Commonly used thresholds for interpreting p-values are:

p < 0.01: Strong evidence against the null hypothesis. This is often considered very strong evidence.

0.01 ≤ p < 0.05: Moderate evidence against the null hypothesis. This is considered fairly strong evidence.

0.05 ≤ p < 0.1: Weak evidence against the null hypothesis. This is considered some evidence, but it's not very strong.

p ≥ 0.1: Weak evidence against the null hypothesis. This is often considered weak evidence.


"""

X.head()

c=0
for i in X.columns:
  class_0_data = df.loc[df['Final_score'] == 0, i]
  class_1_data = df.loc[df['Final_score'] == 1, i]

  t_statistic, p_value = ttest_ind(class_0_data, class_1_data)
  if p_value < 0.01:
    c=c+1
    print("for feature ",i)
    print("T-statistic:", t_statistic)
    print("P-value:", p_value)
print(c, "of the 768 features in X has p_value less than 0.01")

from sklearn.metrics import jaccard_score
y_pred = knn_classifier.predict(X)
y_true=y
jaccard_index = jaccard_score(y_true, y_pred)
print("Jaccard Index:", jaccard_index)

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model.fit(X_train, y_train)

# Calculate training set accuracy
train_accuracy = model.score(X_train, y_train)
print(f"Training Set Accuracy: {train_accuracy}")

# Get the depth of the tree
tree_depth = model.get_depth()
print(f"Tree Depth: {tree_depth}")

import matplotlib.pyplot as plt
from sklearn import tree

# Assuming 'model' is your trained DecisionTreeClassifier
plt.figure(figsize=(15, 10))  # Set the figure size (adjust as needed)
tree.plot_tree(model, filled=True, feature_names=X.columns)  # Adjust feature names if necessary
plt.show()

mlmodel=DecisionTreeClassifier(max_depth=5)

mlmodel.fit(X_train, y_train)

# Calculate training set accuracy
train2_accuracy = mlmodel.score(X_train, y_train)
print(f"Training Set Accuracy: {train2_accuracy}")

# Get the depth of the tree
tree2_depth = mlmodel.get_depth()
print(f"Tree Depth: {tree2_depth}")

# Assuming 'model' is your trained DecisionTreeClassifier
plt.figure(figsize=(15, 10))  # Set the figure size (adjust as needed)
tree.plot_tree(mlmodel, filled=True, feature_names=X.columns)  # Adjust feature names if necessary
plt.show()

emodel=DecisionTreeClassifier(criterion="entropy")
emodel.fit(X_train, y_train)

# Calculate training set accuracy
traine_accuracy = emodel.score(X_train, y_train)
print(f"Training Set Accuracy: {traine_accuracy}")

# Get the depth of the tree
etree_depth = emodel.get_depth()
print(f"Tree Depth: {etree_depth}")

# Assuming 'emodel' is your trained DecisionTreeClassifier with entropy criterion
plt.figure(figsize=(15, 10))  # Set the figure size (adjust as needed)
tree.plot_tree(emodel, filled=True, feature_names=X.columns)  # Adjust feature names if necessary
plt.show()